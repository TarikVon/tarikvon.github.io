<!doctypehtml><html lang=zh-CN><meta charset=UTF-8><meta content=width=device-width name=viewport><meta content=#222 name=theme-color><meta content="Hexo 7.0.0" name=generator><link href=/images/apple-touch-icon-von.png rel=apple-touch-icon sizes=180x180><link href=/images/von-32x32-next.png rel=icon sizes=32x32 type=image/png><link href=/images/von-16x16-next.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/apple-touch-icon-von.png rel=mask-icon><link href=/css/main.css rel=stylesheet><link crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css integrity=sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU= rel=stylesheet><link crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css integrity=sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE= rel=stylesheet><script class=next-config data-name=main type=application/json>{"hostname":"www.tarikvon.cn","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src=/js/config.js></script><meta content="本实验主要介绍基于 modelarts 的 notebook 开发环境，来进行 LSTM 模型的训练->推理的代码实战开发和运行。" name=description><meta content=article property=og:type><meta content="华为云开发者实验：LSTM 模型生成文本" property=og:title><meta content=http://www.tarikvon.cn/2024/07/17/labNote-LSTM/index.html property=og:url><meta content="Von's Blog" property=og:site_name><meta content="本实验主要介绍基于 modelarts 的 notebook 开发环境，来进行 LSTM 模型的训练->推理的代码实战开发和运行。" property=og:description><meta content=zh_CN property=og:locale><meta content=http://www.tarikvon.cn/2024/07/17/labNote-LSTM/image/notes/1721202420900.png property=og:image><meta content=2024-07-17T08:32:02.000Z property=article:published_time><meta content=2024-07-17T08:32:18.641Z property=article:modified_time><meta content="Tarik Von" property=article:author><meta content=Python property=article:tag><meta content=NLP property=article:tag><meta content=LSTM property=article:tag><meta content=RNN property=article:tag><meta content="Huawei Cloud" property=article:tag><meta content=ModelArts property=article:tag><meta content="Jupyter Notebook" property=article:tag><meta content=summary name=twitter:card><meta content=http://www.tarikvon.cn/2024/07/17/labNote-LSTM/image/notes/1721202420900.png name=twitter:image><link href=http://www.tarikvon.cn/2024/07/17/labNote-LSTM/ rel=canonical><script class=next-config data-name=page type=application/json>{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://www.tarikvon.cn/2024/07/17/labNote-LSTM/","path":"2024/07/17/labNote-LSTM/","title":"华为云开发者实验：LSTM 模型生成文本"}</script><script class=next-config data-name=calendar type=application/json>""</script><title>华为云开发者实验：LSTM 模型生成文本 | Von's Blog</title><script src=/js/third-party/analytics/baidu-analytics.js></script><script async src=https://hm.baidu.com/hm.js?82f83f20674b422f119ed5514b2b3c7d></script><script async src=/lib/fireworks.js></script><noscript><link href=/css/noscript.css rel=stylesheet></noscript><!-- hexo injector head_end start --><link href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css rel=stylesheet><!-- hexo injector head_end end --><body class=use-motion itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><div class=column><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <i class=logo-line></i> <p class=site-title>Von's Blog</p> <i class=logo-line></i> </a><p class=site-subtitle itemprop=description>冯格列斯酒馆绝赞营业中~</div><div class=site-nav-right><div class="toggle popup-trigger" aria-label=搜索 role=button></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="fa fa-user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="fa fa-th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="fa fa-archive fa-fw"></i>归档</a><li class="menu-item menu-item-tools"><a href=/tools/ rel=section><i class="fa fa-toolbox fa-fw"></i>工具箱</a></ul></nav></header><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><div class=sidebar-panel-container><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class=nav><li class="nav-item nav-level-1"><a class=nav-link href=#%E5%AE%9E%E9%AA%8C%E7%9B%AE%E6%A0%87%E4%B8%8E%E5%9F%BA%E6%9C%AC%E8%A6%81%E6%B1%82><span class=nav-number>1.</span> <span class=nav-text> 实验目标与基本要求</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#%E4%BB%BB%E5%8A%A1%E4%B8%80%E5%88%9B%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83><span class=nav-number>1.1.</span> <span class=nav-text> 任务一：创建开发环境</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-1-%E9%85%8D%E7%BD%AE-notebook-%E5%8F%82%E6%95%B0><span class=nav-number>1.1.1.</span> <span class=nav-text> 步骤 1 配置 notebook 参数</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E4%BB%BB%E5%8A%A1%E4%BA%8C-%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81><span class=nav-number>1.2.</span> <span class=nav-text> 任务二: 运行代码</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-1-%E5%AE%89%E8%A3%85%E9%9C%80%E8%A6%81%E7%9A%84%E5%8C%85><span class=nav-number>1.2.1.</span> <span class=nav-text> 步骤 1 安装需要的包</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-2-%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE><span class=nav-number>1.2.2.</span> <span class=nav-text> 步骤 2 获取数据</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-3-%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9D%A5%E6%BA%90%E5%92%8C%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86><span class=nav-number>1.2.3.</span> <span class=nav-text> 步骤 3 数据集来源和读取数据集</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-4-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86><span class=nav-number>1.2.4.</span> <span class=nav-text> 步骤 4 数据预处理</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-5-%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0><span class=nav-number>1.2.5.</span> <span class=nav-text> 步骤 5 定义训练参数</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-6-%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84><span class=nav-number>1.2.6.</span> <span class=nav-text> 步骤 6 定义模型结构</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-7-%E5%AE%9A%E4%B9%89%E9%A6%96%E5%8F%A5%E7%94%9F%E6%88%90%E8%AF%97%E6%AD%8C%E5%92%8C%E8%97%8F%E5%A4%B4%E8%AF%97%E5%87%BD%E6%95%B0><span class=nav-number>1.2.7.</span> <span class=nav-text> 步骤 7 定义首句生成诗歌和藏头诗函数</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-8-%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0><span class=nav-number>1.2.8.</span> <span class=nav-text> 步骤 8 定义模型和训练函数</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-9-%E5%AE%9A%E4%B9%89%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0%E5%B9%B6%E4%B8%94%E6%B5%8B%E8%AF%95%E7%94%9F%E6%88%90%E7%BB%93%E6%9E%9C><span class=nav-number>1.2.9.</span> <span class=nav-text> 步骤 9 定义预测函数并且测试生成结果</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E6%AD%A5%E9%AA%A4-10-%E6%9F%A5%E7%9C%8B%E8%AE%AD%E7%BB%83%E8%BE%93%E5%87%BA%E7%9A%84%E6%A8%A1%E5%9E%8B><span class=nav-number>1.2.10.</span> <span class=nav-text> 步骤 10 查看训练输出的模型</span></a></ol></ol></ol></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop=author itemscope itemtype=http://schema.org/Person><img alt="Tarik Von" class=site-author-image itemprop=image src=http://q.qlogo.cn/headimg_dl?dst_uin=2758557228&spec=640&img_type=jpg><p class=site-author-name itemprop=name>Tarik Von<div class=site-description itemprop=description></div></div><div class="site-state-wrap animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>13</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>5</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>45</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author animated"><span class=links-of-author-item> <a rel="noopener me" title="GitHub → https://github.com/TarikVon" href=https://github.com/TarikVon target=_blank><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class=links-of-author-item> <a rel="noopener me" title="Bilibili → https://space.bilibili.com/133633241" href=https://space.bilibili.com/133633241 target=_blank><i class="fab fa-bilibili fa-fw"></i>Bilibili</a> </span><span class=links-of-author-item> <a rel="noopener me" title="Twitter → https://twitter.com/Tarik_Von" href=https://twitter.com/Tarik_Von target=_blank><i class="fab fa-twitter fa-fw"></i>Twitter</a> </span><span class=links-of-author-item> <a rel="noopener me" title="YouTube → https://www.youtube.com/@TarikVon" href=https://www.youtube.com/@TarikVon target=_blank><i class="fab fa-youtube fa-fw"></i>YouTube</a> </span></div></div></div><div><iframe border=0 frameborder=no height=86 marginheight=0 marginwidth=0 src=https://music.163.com/outchain/player?type=2&id=1398802958&auto=0&height=66 width=330></iframe><script async src=https://rf.revolvermaps.com/0/0/8.js?i=5vuqjbxfa40&m=7&c=ff0000&cr1=ffffff&f=arial&l=33></script></div></div></aside></div><div class="main-inner post posts-expand"><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=http://www.tarikvon.cn/2024/07/17/labNote-LSTM/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=http://q.qlogo.cn/headimg_dl?dst_uin=2758557228&spec=640&img_type=jpg itemprop=image> <meta content="Tarik Von" itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content="Von's Blog" itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="华为云开发者实验：LSTM 模型生成文本 | Von's Blog" itemprop=name> <meta itemprop=description> </span><header class=post-header><h1 itemprop="name headline" class=post-title>华为云开发者实验：LSTM 模型生成文本</h1><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2024-07-17 16:32:02 / 修改时间：16:32:18" datetime=2024-07-17T16:32:02+08:00>2024-07-17</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/notes/ itemprop=url rel=index><span itemprop=name>notes</span></a> </span> </span><span class=post-meta-item title=本文字数> <span class=post-meta-item-icon> <i class="far fa-file-word"></i> </span> <span class=post-meta-item-text>本文字数：</span> <span>4.6k</span> </span><span class=post-meta-item title=阅读时长> <span class=post-meta-item-icon> <i class="far fa-clock"></i> </span> <span class=post-meta-item-text>阅读时长 ≈</span> <span>17 分钟</span> </span></div></div></header><div class=post-body itemprop=articleBody><h1 id=实验目标与基本要求><a class=markdownIt-Anchor href=#实验目标与基本要求></a> 实验目标与基本要求</h1><ul><li>理解 LSTM 模型：掌握长短期记忆网络（LSTM）的基本原理和结构。<li>熟悉 ModelArts 平台：了解华为云 ModelArts 平台的基本功能和操作流程。<li>掌握 Notebook 开发环境：学习如何在 ModelArts 的 Notebook 环境中编写和运行代码。</ul><h2 id=任务一创建开发环境><a class=markdownIt-Anchor href=#任务一创建开发环境></a> 任务一：创建开发环境</h2><h3 id=步骤-1-配置-notebook-参数><a class=markdownIt-Anchor href=#步骤-1-配置-notebook-参数></a> 步骤 1 配置 notebook 参数</h3><p>主要参数信息如下，其余配置请保持默认配置<ul><li>名称：notebook-LSTM(名称固定)<li>镜像：选择“公共镜像”，并选择“pytorch1.8-cuda10.2-cudnn7-ubuntu18.04”<li>资源类型：选择“公共资源池”<li>类型：选择“GPU”<li>规格：选择“GPU: 1*Pnt1(16GB)|CPU: 8 核 64GB”</ul><h2 id=任务二-运行代码><a class=markdownIt-Anchor href=#任务二-运行代码></a> 任务二: 运行代码</h2><p>对下文的每个代码片段，在 PyTorch-1.8 开发环境中，新建一个代码块进行运行：<h3 id=步骤-1-安装需要的包><a class=markdownIt-Anchor href=#步骤-1-安装需要的包></a> 步骤 1 安装需要的包</h3><p>输入：<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>!pip install torchnet</span><br></pre></table></figure><p>输出：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line>Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple</span><br><span class=line>Requirement already satisfied: torchnet in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (0.0.4)</span><br><span class=line>Requirement already satisfied: visdom in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from torchnet) (0.2.4)</span><br><span class=line>s (from requests->visdom->torchnet) (1.26.12)</span><br><span class=line>Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from requests->visdom->torchnet) (2.0.12)</span><br><span class=line>Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from requests->visdom->torchnet) (2022.9.24)</span><br><span class=line>WARNING: You are using pip version 21.0.1; however, version 24.0 is available.</span><br><span class=line>You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.8/bin/python3.7 -m pip install --upgrade pip' command.</span><br></pre></table></figure><h3 id=步骤-2-获取数据><a class=markdownIt-Anchor href=#步骤-2-获取数据></a> 步骤 2 获取数据</h3><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> moxing <span class=keyword>as</span> mox</span><br><span class=line>mox.file.copy_parallel(<span class=string>'obs://modelarts-labs-bj4-v2/course/NLP_Course/LSTM'</span>,<span class=string>'LSTM_poem-master'</span>)</span><br></pre></table></figure><p>输出结果可刷新查看右边的文件夹：<br> <img alt=1721202420900 src=image/notes/1721202420900.png><h3 id=步骤-3-数据集来源和读取数据集><a class=markdownIt-Anchor href=#步骤-3-数据集来源和读取数据集></a> 步骤 3 数据集来源和读取数据集</h3><p>本次采用的是唐诗数据集，一共有接近 60000 首唐诗，不需要标签，因为 AI 自动写诗可以看成是语言模型的一个应用<p>其中一首诗的一句如下：<table><thead><tr><th>上句<th>下句<tbody><tr><td>度 门 能 不 访<td>冒 雪 屡 西 东</table><p>任务定义：给出一首诗的开头几个词，或者首句（随便），续写之后的句子。<p>测试结果初窥：<table><thead><tr><th>输入<th>上句<th>下句<tbody><tr><td>度 门 能 不<td>度门能不见<td>今日复不知<tr><td>举头望<td>举头望山中<td>一年一年年<tr><td>会当<td>会当年少年<td>春风吹新开</table><p><strong>读取数据集</strong><p>输入：<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line>%cd /home/ma-user/work/LSTM_poem-master</span><br><span class=line><span class=keyword>import</span> numpy <span class=keyword>as</span> np</span><br><span class=line>file_path=<span class=string>"tang.npz"</span></span><br><span class=line>poem=np.load(file_path,allow_pickle=<span class=literal>True</span>)</span><br><span class=line>poem.files</span><br></pre></table></figure><p>查看结果：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>/home/ma-user/work/LSTM_poem-master</span><br><span class=line>['ix2word', 'word2ix', 'data']</span><br></pre></table></figure><p>一些其他操作：<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>ix2word,word2ix,data=poem[<span class=string>'ix2word'</span>],poem[<span class=string>'word2ix'</span>],poem[<span class=string>'data'</span>]</span><br><span class=line>data.shape</span><br></pre></table></figure><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>(57580, 125)</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line>char2ix=word2ix.item()</span><br><span class=line>ix2char=ix2word.item()</span><br><span class=line>vocab_size=<span class=built_in>len</span>(char2ix)</span><br><span class=line>vocab_size</span><br></pre></table></figure><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>8293</span><br></pre></table></figure><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line>pad_id=char2ix[<span class=string>"&LT/s>"</span>]</span><br><span class=line>start_id=char2ix[<span class=string>"&LTSTART>"</span>]</span><br><span class=line>end_id=char2ix[<span class=string>"&LTEOP>"</span>]</span><br><span class=line><span class=built_in>print</span>(pad_id,start_id,end_id)</span><br></pre></table></figure><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>8292 8291 8290</span><br></pre></table></figure><h3 id=步骤-4-数据预处理><a class=markdownIt-Anchor href=#步骤-4-数据预处理></a> 步骤 4 数据预处理</h3><p>减少训练的量，选 2000 首诗进行训练。<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>data=data[:<span class=number>2000</span>]</span><br><span class=line>data.shape</span><br></pre></table></figure><p>结果：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>(2000, 125)</span><br></pre></table></figure><p>把 <code>&LT/s></code> 放在放到后面，将数据进行转换。<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br></pre><td class=code><pre><span class=line><span class=comment>#把&LT/s>放在放到后面。</span></span><br><span class=line><span class=keyword>def</span> <span class="title function_">reverse</span>(<span class=params>poem</span>):</span><br><span class=line>    ind=np.argwhere(poem==start_id).item()</span><br><span class=line>    new_poem=poem[ind:<span class=built_in>len</span>(poem)]</span><br><span class=line>    pad=poem[<span class=number>0</span>:ind]</span><br><span class=line>    <span class=keyword>return</span> np.hstack((new_poem,pad))</span><br><span class=line></span><br><span class=line><span class=comment>#将数据进行转换。</span></span><br><span class=line><span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(<span class=built_in>len</span>(data)):</span><br><span class=line>    data[i]=reverse(data[i])</span><br><span class=line><span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(data.shape[<span class=number>1</span>]):</span><br><span class=line>    <span class=built_in>print</span>(ix2char[data[<span class=number>3</span>][i]],end=<span class=string>" "</span>)</span><br></pre></table></figure><p>结果：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>&LTSTART> 庭 树 忽 已 暗 ， 故 人 那 不 来 。 祗 因 厌 烦 暑 ， 永 日 坐 霜 台 。 &LTEOP> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s> &LT/s></span><br></pre></table></figure><h3 id=步骤-5-定义训练参数><a class=markdownIt-Anchor href=#步骤-5-定义训练参数></a> 步骤 5 定义训练参数</h3><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br></pre><td class=code><pre><span class=line><span class=keyword>class</span> <span class="title class_">Config</span>(<span class="title class_ inherited__">object</span>):</span><br><span class=line>    num_layers = <span class=number>3</span>  <span class=comment># LSTM层数</span></span><br><span class=line>    data_path = <span class=string>'data/'</span>  <span class=comment># 诗歌的文本文件存放路径</span></span><br><span class=line>    pickle_path = <span class=string>'tang.npz'</span>  <span class=comment># 预处理好的二进制文件</span></span><br><span class=line>    author = <span class=literal>None</span>  <span class=comment># 只学习某位作者的诗歌</span></span><br><span class=line>    constrain = <span class=literal>None</span>  <span class=comment># 长度限制</span></span><br><span class=line>    category = <span class=string>'poet.tang'</span>  <span class=comment># 类别，唐诗还是宋诗歌(poet.song)</span></span><br><span class=line>    <span class=comment># lr = 1e-3</span></span><br><span class=line>    lr = <span class=number>1e-4</span></span><br><span class=line>    weight_decay = <span class=number>1e-4</span></span><br><span class=line>    use_gpu = <span class=literal>True</span></span><br><span class=line>    <span class=comment>#epoch = 10</span></span><br><span class=line>    epoch = <span class=number>20</span></span><br><span class=line>    <span class=comment># batch_size = 16</span></span><br><span class=line>    batch_size = <span class=number>32</span></span><br><span class=line>    maxlen = <span class=number>125</span>  <span class=comment># 超过这个长度的之后字被丢弃，小于这个长度的在前面补空格</span></span><br><span class=line>    plot_every = <span class=number>200</span>  <span class=comment># 每20个batch 可视化一次</span></span><br><span class=line>    <span class=comment># use_env = True # 是否使用visodm</span></span><br><span class=line>    env = <span class=string>'poetry'</span>  <span class=comment># visdom env</span></span><br><span class=line>    max_gen_len = <span class=number>200</span>  <span class=comment># 生成诗歌最长长度</span></span><br><span class=line>    debug_file = <span class=string>'/tmp/debugp'</span></span><br><span class=line>    model_path = <span class=string>"/home/ma-user/work/LSTM_poem-master/checkpoints/tang_new.pth"</span>  <span class=comment># 预训练模型路径</span></span><br><span class=line>    prefix_words = <span class=string>'仙路尽头谁为峰？一见无始道成空。'</span>  <span class=comment># 不是诗歌的组成部分，用来控制生成诗歌的意境</span></span><br><span class=line>    start_words = <span class=string>'闲云潭影日悠悠'</span>  <span class=comment># 诗歌开始</span></span><br><span class=line>    acrostic = <span class=literal>False</span>  <span class=comment># 是否是藏头诗</span></span><br><span class=line>    model_prefix = <span class=string>'checkpoints/'</span>  <span class=comment># 模型保存路径</span></span><br><span class=line>    embedding_dim = <span class=number>256</span></span><br><span class=line>    hidden_dim = <span class=number>512</span></span><br></pre></table></figure><p>本段无输出<h3 id=步骤-6-定义模型结构><a class=markdownIt-Anchor href=#步骤-6-定义模型结构></a> 步骤 6 定义模型结构</h3><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> torch.nn <span class=keyword>as</span> nn</span><br><span class=line></span><br><span class=line><span class=keyword>class</span> <span class="title class_">PoetryModel</span>(nn.Module):</span><br><span class=line>    <span class=keyword>def</span> <span class="title function_">__init__</span>(<span class=params>self, vocab_size, embedding_dim, hidden_dim</span>):</span><br><span class=line>        <span class=built_in>super</span>(PoetryModel, self).__init__()</span><br><span class=line>        self.hidden_dim = hidden_dim</span><br><span class=line>        <span class=comment># 词向量层，词表大小 * 向量维度</span></span><br><span class=line>        self.embeddings = nn.Embedding(vocab_size, embedding_dim)</span><br><span class=line>        <span class=comment># 网络主要结构</span></span><br><span class=line>        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers=Config.num_layers)</span><br><span class=line>        <span class=comment># 进行分类</span></span><br><span class=line>        self.linear = nn.Linear(self.hidden_dim, vocab_size)</span><br><span class=line></span><br><span class=line>    <span class=keyword>def</span> <span class="title function_">forward</span>(<span class=params>self, <span class=built_in>input</span>, hidden=<span class=literal>None</span></span>):</span><br><span class=line>        seq_len, batch_size = <span class=built_in>input</span>.size()</span><br><span class=line>        <span class=comment>#print(input.shape)</span></span><br><span class=line>        <span class=keyword>if</span> hidden <span class=keyword>is</span> <span class=literal>None</span>:</span><br><span class=line>            h_0 = <span class=built_in>input</span>.data.new(Config.num_layers, batch_size, self.hidden_dim).fill_(<span class=number>0</span>).<span class=built_in>float</span>()</span><br><span class=line>            c_0 = <span class=built_in>input</span>.data.new(Config.num_layers, batch_size, self.hidden_dim).fill_(<span class=number>0</span>).<span class=built_in>float</span>()</span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            h_0, c_0 = hidden</span><br><span class=line>        <span class=comment># 输入 序列长度 * batch(每个汉字是一个数字下标)，</span></span><br><span class=line>        <span class=comment># 输出 序列长度 * batch * 向量维度</span></span><br><span class=line>        embeds = self.embeddings(<span class=built_in>input</span>)</span><br><span class=line>        <span class=comment># 输出hidden的大小： 序列长度 * batch * hidden_dim</span></span><br><span class=line>        output, hidden = self.lstm(embeds, (h_0, c_0))</span><br><span class=line>        output = self.linear(output.view(seq_len * batch_size, -<span class=number>1</span>))</span><br><span class=line>        <span class=keyword>return</span> output, hidden</span><br></pre></table></figure><p>本段无输出<h3 id=步骤-7-定义首句生成诗歌和藏头诗函数><a class=markdownIt-Anchor href=#步骤-7-定义首句生成诗歌和藏头诗函数></a> 步骤 7 定义首句生成诗歌和藏头诗函数</h3><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br><span class=line>80</span><br><span class=line>81</span><br><span class=line>82</span><br><span class=line>83</span><br><span class=line>84</span><br><span class=line>85</span><br><span class=line>86</span><br><span class=line>87</span><br><span class=line>88</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> torch <span class=keyword>as</span> t</span><br><span class=line><span class=keyword>import</span> numpy <span class=keyword>as</span> np</span><br><span class=line><span class=keyword>from</span> torch.utils.data <span class=keyword>import</span> DataLoader</span><br><span class=line><span class=keyword>from</span> torch <span class=keyword>import</span> optim</span><br><span class=line><span class=keyword>from</span> torch <span class=keyword>import</span> nn</span><br><span class=line><span class=keyword>from</span> torchnet <span class=keyword>import</span> meter</span><br><span class=line><span class=keyword>import</span> tqdm</span><br><span class=line></span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=comment># 给定首句生成诗歌</span></span><br><span class=line><span class=keyword>def</span> <span class="title function_">generate</span>(<span class=params>model, start_words, ix2word, word2ix, prefix_words=<span class=literal>None</span></span>):</span><br><span class=line>    results = <span class=built_in>list</span>(start_words)</span><br><span class=line>    start_words_len = <span class=built_in>len</span>(start_words)</span><br><span class=line>    <span class=comment># 第一个词语是&LTSTART></span></span><br><span class=line>    <span class=built_in>input</span> = t.Tensor([word2ix[<span class=string>'&LTSTART>'</span>]]).view(<span class=number>1</span>, <span class=number>1</span>).long()</span><br><span class=line>    <span class=keyword>if</span> Config.use_gpu:</span><br><span class=line>        <span class=built_in>input</span> = <span class=built_in>input</span>.cuda()</span><br><span class=line>    hidden = <span class=literal>None</span></span><br><span class=line></span><br><span class=line>    <span class=comment># 若有风格前缀，则先用风格前缀生成hidden</span></span><br><span class=line>    <span class=keyword>if</span> prefix_words:</span><br><span class=line>        <span class=comment># 第一个input是&LTSTART>，后面就是prefix中的汉字</span></span><br><span class=line>        <span class=comment># 第一个hidden是None，后面就是前面生成的hidden</span></span><br><span class=line>        <span class=keyword>for</span> word <span class=keyword>in</span> prefix_words:</span><br><span class=line>            output, hidden = model(<span class=built_in>input</span>, hidden)</span><br><span class=line>            <span class=built_in>input</span> = <span class=built_in>input</span>.data.new([word2ix[word]]).view(<span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>    <span class=comment># 开始真正生成诗句，如果没有使用风格前缀，则hidden = None，input = &LTSTART></span></span><br><span class=line>    <span class=comment># 否则，input就是风格前缀的最后一个词语，hidden也是生成出来的</span></span><br><span class=line>    <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(Config.max_gen_len):</span><br><span class=line>        output, hidden = model(<span class=built_in>input</span>, hidden)</span><br><span class=line>        <span class=comment># print(output.shape)</span></span><br><span class=line>        <span class=comment># 如果还在诗句内部，输入就是诗句的字，不取出结果，只为了得到</span></span><br><span class=line>        <span class=comment># 最后的hidden</span></span><br><span class=line>        <span class=keyword>if</span> i < start_words_len:</span><br><span class=line>            w = results[i]</span><br><span class=line>            <span class=built_in>input</span> = <span class=built_in>input</span>.data.new([word2ix[w]]).view(<span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>        <span class=comment># 否则将output作为下一个input进行</span></span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            <span class=comment># print(output.data[0].topk(1))</span></span><br><span class=line>            top_index = output.data[<span class=number>0</span>].topk(<span class=number>1</span>)[<span class=number>1</span>][<span class=number>0</span>].item()</span><br><span class=line>            w = ix2word[top_index]</span><br><span class=line>            results.append(w)</span><br><span class=line>            <span class=built_in>input</span> = <span class=built_in>input</span>.data.new([top_index]).view(<span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>        <span class=keyword>if</span> w == <span class=string>'&LTEOP>'</span>:</span><br><span class=line>            <span class=keyword>del</span> results[-<span class=number>1</span>]</span><br><span class=line>            <span class=keyword>break</span></span><br><span class=line>    <span class=keyword>return</span> results</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=comment># 生成藏头诗</span></span><br><span class=line><span class=keyword>def</span> <span class="title function_">gen_acrostic</span>(<span class=params>model, start_words, ix2word, word2ix, prefix_words=<span class=literal>None</span></span>):</span><br><span class=line>    result = []</span><br><span class=line>    start_words_len = <span class=built_in>len</span>(start_words)</span><br><span class=line>    <span class=built_in>input</span> = (t.Tensor([word2ix[<span class=string>'&LTSTART>'</span>]]).view(<span class=number>1</span>, <span class=number>1</span>).long())</span><br><span class=line>    <span class=keyword>if</span> Config.use_gpu:</span><br><span class=line>        <span class=built_in>input</span> = <span class=built_in>input</span>.cuda()</span><br><span class=line>    <span class=comment># 指示已经生成了几句藏头诗</span></span><br><span class=line>    index = <span class=number>0</span></span><br><span class=line>    pre_word = <span class=string>'&LTSTART>'</span></span><br><span class=line>    hidden = <span class=literal>None</span></span><br><span class=line></span><br><span class=line>    <span class=comment># 存在风格前缀，则生成hidden</span></span><br><span class=line>    <span class=keyword>if</span> prefix_words:</span><br><span class=line>        <span class=keyword>for</span> word <span class=keyword>in</span> prefix_words:</span><br><span class=line>            output, hidden = model(<span class=built_in>input</span>, hidden)</span><br><span class=line>            <span class=built_in>input</span> = (<span class=built_in>input</span>.data.new([word2ix[word]])).view(<span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line></span><br><span class=line>    <span class=comment># 开始生成诗句</span></span><br><span class=line>    <span class=keyword>for</span> i <span class=keyword>in</span> <span class=built_in>range</span>(Config.max_gen_len):</span><br><span class=line>        output, hidden = model(<span class=built_in>input</span>, hidden)</span><br><span class=line>        top_index = output.data[<span class=number>0</span>].topk(<span class=number>1</span>)[<span class=number>1</span>][<span class=number>0</span>].item()</span><br><span class=line>        w = ix2word[top_index]</span><br><span class=line>        <span class=comment># 说明上个字是句末</span></span><br><span class=line>        <span class=keyword>if</span> pre_word <span class=keyword>in</span> {<span class=string>'。'</span>, <span class=string>'，'</span>, <span class=string>'?'</span>, <span class=string>'！'</span>, <span class=string>'&LTSTART>'</span>}:</span><br><span class=line>            <span class=keyword>if</span> index == start_words_len:</span><br><span class=line>                <span class=keyword>break</span></span><br><span class=line>            <span class=keyword>else</span>:</span><br><span class=line>                w = start_words[index]</span><br><span class=line>                index += <span class=number>1</span></span><br><span class=line>                <span class=comment># print(w,word2ix[w])</span></span><br><span class=line>                <span class=built_in>input</span> = (<span class=built_in>input</span>.data.new([word2ix[w]])).view(<span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>        <span class=keyword>else</span>:</span><br><span class=line>            <span class=built_in>input</span> = (<span class=built_in>input</span>.data.new([top_index])).view(<span class=number>1</span>, <span class=number>1</span>)</span><br><span class=line>        result.append(w)</span><br><span class=line>        pre_word = w</span><br><span class=line>    <span class=keyword>return</span> result</span><br></pre></table></figure><p>本段无输出<h3 id=步骤-8-定义模型和训练函数><a class=markdownIt-Anchor href=#步骤-8-定义模型和训练函数></a> 步骤 8 定义模型和训练函数</h3><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br><span class=line>69</span><br><span class=line>70</span><br><span class=line>71</span><br><span class=line>72</span><br><span class=line>73</span><br><span class=line>74</span><br><span class=line>75</span><br><span class=line>76</span><br><span class=line>77</span><br><span class=line>78</span><br><span class=line>79</span><br><span class=line>80</span><br><span class=line>81</span><br><span class=line>82</span><br><span class=line>83</span><br></pre><td class=code><pre><span class=line>%cd /home/ma-user/work/</span><br><span class=line><span class=keyword>import</span> os</span><br><span class=line><span class=keyword>import</span> torch <span class=keyword>as</span> t</span><br><span class=line><span class=keyword>import</span> numpy <span class=keyword>as</span> np</span><br><span class=line><span class=keyword>from</span> torch.utils.data <span class=keyword>import</span> DataLoader</span><br><span class=line><span class=keyword>from</span> torch <span class=keyword>import</span> optim</span><br><span class=line><span class=keyword>from</span> torch <span class=keyword>import</span> nn</span><br><span class=line><span class=comment># from model import *</span></span><br><span class=line><span class=keyword>from</span> torchnet <span class=keyword>import</span> meter</span><br><span class=line><span class=keyword>import</span> tqdm</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=keyword>def</span> <span class="title function_">train</span>():</span><br><span class=line>    <span class=keyword>if</span> Config.use_gpu:</span><br><span class=line>        Config.device = t.device(<span class=string>"cuda"</span>)</span><br><span class=line>    <span class=keyword>else</span>:</span><br><span class=line>        Config.device = t.device(<span class=string>"cpu"</span>)</span><br><span class=line>    device = Config.device</span><br><span class=line>    <span class=comment># 获取数据</span></span><br><span class=line>    datas = np.load(<span class=string>"LSTM_poem-master/tang.npz"</span>, allow_pickle=<span class=literal>True</span>)</span><br><span class=line>    data = datas[<span class=string>'data'</span>]</span><br><span class=line>    ix2word = datas[<span class=string>'ix2word'</span>].item()</span><br><span class=line>    word2ix = datas[<span class=string>'word2ix'</span>].item()</span><br><span class=line>    data = t.from_numpy(data)</span><br><span class=line>    dataloader = DataLoader(data,</span><br><span class=line>                            batch_size=Config.batch_size,</span><br><span class=line>                            shuffle=<span class=literal>True</span>,</span><br><span class=line>                            num_workers=<span class=number>2</span>)</span><br><span class=line></span><br><span class=line>    <span class=comment># 定义模型</span></span><br><span class=line>    model = PoetryModel(<span class=built_in>len</span>(word2ix),</span><br><span class=line>                        embedding_dim=Config.embedding_dim,</span><br><span class=line>                        hidden_dim = Config.hidden_dim)</span><br><span class=line>    Configimizer = optim.Adam(model.parameters(),lr=Config.lr)</span><br><span class=line>    criterion = nn.CrossEntropyLoss()</span><br><span class=line>    <span class=keyword>if</span> Config.model_path:</span><br><span class=line>        model.load_state_dict(t.load(Config.model_path,map_location=<span class=string>'cpu'</span>))</span><br><span class=line>    <span class=comment># 转移到相应计算设备上</span></span><br><span class=line>    model.to(device)</span><br><span class=line>    loss_meter = meter.AverageValueMeter()</span><br><span class=line></span><br><span class=line>    save_dir = <span class=string>'/home/ma-user/work/LSTM_poem-master/Output'</span></span><br><span class=line></span><br><span class=line></span><br><span class=line>    <span class=comment># 进行训练</span></span><br><span class=line>    f = <span class=built_in>open</span>(<span class=string>'result.txt'</span>,<span class=string>'w'</span>)</span><br><span class=line>    <span class=keyword>for</span> epoch <span class=keyword>in</span> <span class=built_in>range</span>(Config.epoch):</span><br><span class=line>        loss_meter.reset()</span><br><span class=line>        <span class=keyword>for</span> li,data_ <span class=keyword>in</span> tqdm.tqdm(<span class=built_in>enumerate</span>(dataloader)):</span><br><span class=line>            <span class=comment>#print(data_.shape)</span></span><br><span class=line>            data_ = data_.long().transpose(<span class=number>1</span>,<span class=number>0</span>).contiguous()</span><br><span class=line>            <span class=comment># 注意这里，也转移到了计算设备上</span></span><br><span class=line>            data_ = data_.to(device)</span><br><span class=line>            Configimizer.zero_grad()</span><br><span class=line>            <span class=comment># n个句子，前n-1句作为输入，后n-1句作为输出，二者一一对应</span></span><br><span class=line>            input_,target = data_[:-<span class=number>1</span>,:],data_[<span class=number>1</span>:,:]</span><br><span class=line>            output,_ = model(input_)</span><br><span class=line>            <span class=comment># print("Here",output.shape)</span></span><br><span class=line>            <span class=comment># 这里为什么view(-1)</span></span><br><span class=line>            <span class=comment># print(target.shape,target.view(-1).shape)</span></span><br><span class=line>            loss = criterion(output,target.view(-<span class=number>1</span>))</span><br><span class=line>            loss.backward()</span><br><span class=line>            Configimizer.step()</span><br><span class=line>            loss_meter.add(loss.item())</span><br><span class=line>            <span class=comment># 进行可视化</span></span><br><span class=line>            <span class=keyword>if</span> (<span class=number>1</span>+li)%Config.plot_every == <span class=number>0</span>:</span><br><span class=line>                <span class=built_in>print</span>(<span class=string>"训练损失为%s"</span>%(<span class=built_in>str</span>(loss_meter.mean)))</span><br><span class=line>                f.write(<span class=string>"训练损失为%s"</span>%(<span class=built_in>str</span>(loss_meter.mean)))</span><br><span class=line>                <span class=keyword>for</span> word <span class=keyword>in</span> <span class=built_in>list</span>(<span class=string>u"春江花朝秋月夜"</span>):</span><br><span class=line>                    gen_poetry = <span class=string>''</span>.join(generate(model,word,ix2word,word2ix))</span><br><span class=line>                    <span class=built_in>print</span>(gen_poetry)</span><br><span class=line>                    f.write(gen_poetry)</span><br><span class=line>                    f.write(<span class=string>"\n\n\n"</span>)</span><br><span class=line>                    f.flush()</span><br><span class=line>        <span class=comment># model_save_path = os.path.join(save_dir, '%s_%s.pth' % (Config.model_prefix, epoch))</span></span><br><span class=line>        <span class=comment># t.save(model.state_dict(), model_save_path)</span></span><br><span class=line>        model_save_path = os.path.join(save_dir, <span class=string>'model_epoch_%s.pth'</span> % epoch)</span><br><span class=line>        t.save(model.state_dict(), model_save_path)</span><br><span class=line></span><br><span class=line></span><br><span class=line><span class=keyword>if</span> __name__ == <span class=string>'__main__'</span>:</span><br><span class=line></span><br><span class=line>    train()</span><br></pre></table></figure><p>结果输出：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br></pre><td class=code><pre><span class=line>/home/ma-user/work</span><br><span class=line>198it [00:12, 16.55it/s]</span><br><span class=line>训练损失为0.6370207652449614</span><br><span class=line>春江潮水连海平，海上明月共潮生。灩灩随波千万里，何处春江无去程。龙舟漾漾枫林远，津邑野花风日暮。不知名物远悠悠，只见渔乡夜闻落。日暮西风摇落时，枫树千竿转回举。林中愁歇多少情，雨后还待夜行客。梦依青嶂上重天，出处皆防陇上园。松根翳重暮归鸟，日晚猎僧眠石门。江鸥一宿五湖水，波摇荡漾澄平碧。林际鹤鸣人未归，江边橘树人应稀。林下酒瓶明月月，年年零落过江头。吾君无事无人识，觉后多为萧寺侯。龟逸四门逃豁讳，</span><br><span class=line>江上为云尉，蚕何贱马蹄。胡笳断行路，河汉送长愁。长劒功皆在，孤舟去自浮。杂雷随盖毂，阴气隔云流。竞就临川拜，差盘密柳游。梅梅蒙放锦，锦蘂堕青油。粉壁交王母，红楼醉画楼。参差盘岫阁，竞结华芳秋。迥比千门路，飘摇两岸愁。遥期方尚往，灞水赋新游。远梦惊阶雪，余香染䌽裘。鸣鸿思不乐，事没事难尤。自窃蹉跎集，欣欣庶厚黎。果辞文翰旧，忝谒子丞余。</span><br><span class=line>花界无多地，烟霞尽日闲。浮名高自显，好是此为邻。静口潜通药，过时即问邻。心知无所念，物外尽君亲。澹荡情无限，抟风事不伸。灯应乌不厌，蝶与泪俱新。似镜疑含泪，垂纶似早春。细霑芳草色，虚以落篱巾。墙似藏峰鹤，藤闻近水鳞。柳夭迷岸翠，莲阁认枝新。保实通周沐，狂流过洞秦。醉眠当宴处，思唱小楼尘。</span><br><span class=line>朝光九霄澹，送子大丈夫。霜露含绮绮，凉衣曜清珰。清夜漏漏丽，清江月霓高。非君在何许，意与时人嗤。忆昔天路遥，游春物芳菲。神仙去何际，鸞舞琼瑶枝。皓齿一以时，悯妖反自怡。炎风入广户，清露含芳思。分辉委素义，清旷为良芝。服意岂云异，至今常坐奇。答之北堂上，时俗羇嚣师。纵广无知己，溘来无定时。我心保真性，何必平生知。</span><br><span class=line>秋天杳茫茫茫如皎，予今欲示吴江间。荷蓑寄茧绕户间，扁舟断歌弄梨枣。沙台衣暖心欲折，雨雪濛濛四江转。庭前一面木脂簪，侧开洞房垂柳深。越人侍女争开口，开窗独倚香帘帏。暂来云雨心寂寞，寥落清光不能返。自然匣中素书珠，解与我心还不著。愿君昨来心自怜，使我愁颜莫如此。日照莲光风动时，高阁东邻来往去。劝尔为君下石文，醍醐只在头陀地。愿得君子好老时，不放一行登四壁。</span><br><span class=line>月出海门寻不定，山东斗中开新壁。初时沽酒不及钱，祝贾经年逐沧海。废船不问邑中儿，秪为不待卢晋生。胡兵驾吹人不起，河嶽已作风尘生。对此何人千万古？炎纲旧识雌殷声。昭阳旧曲慰心室，空令马蹄心自息。秋风霜中鸿雁飞，空把金缸泪销血。行魂不到马头空，远路还思暮天白。落花飞尽空路愁，白羽不成何足贵。看着还经镜底目，一只如刀系时雪。不是老人愁杀人，少年不得还乡人。</span><br><span class=line>202it [00:13,  7.28it/s]</span><br><span class=line>夜梦神州天道忙？定本自通奇制场。四十有生缘此艺，出中更见并天王。五更十二山精女，周转十三声真相。丰铜怪火烧相与，灵通逐水心中识。风吹吹，万草光，二物如是是非王。只有一世古中人，十二石桥迎第一。都持两刀入府名，五将变化如焚云。诸子振尸一如玉，不能终身没杀死。亦能得一个生灵骨，生死由来始知足。圣罪须慈伏武臣，文夫气内随人断。五世功名辨不谐，穷愁错报人生死。</span><br><span class=line></span><br><span class=line>···</span><br><span class=line></span><br><span class=line>1798it [01:55, 16.34it/s]</span><br><span class=line>训练损失为0.5768661327494516</span><br><span class=line>春江潮水连海平，海上明月共潮生。灩灩随波千万里，何处春江无月明？江流宛转遶芳甸，月照花林皆似霰。空里流霜不觉飞，汀上白沙看不见。江天一色无纤尘，皎皎空中孤月轮。江畔何人初见月，江月何年初照人？人生代代无穷已，江月年年秖相似。不知江月待何人？但见长江共云阔，空使人心不同別。世人爱我百余年，且遇佳人养君去。日暮东西头半空，昨日逢君一局禅。</span><br><span class=line>江上为云水，若云有遮家。谁能剪借翔，上出作蛟凰。飞栖蓬莱殿，千寻玉座堂。五丁有嘉蘂，三数藏云芳。娇豔芙蓉姿，衔张凤容珰。筝声入绮弦，歌声转轻芳。恩华委华饰，不敢弄琼瑶。妾身与长游，从此一何长。传鹤出楚门，凭高望长堂。香是香可斫，夜静鱼亦长。隐居无一物，但见此梦长。朝风动小林，春草生绿塘。色入花露落，露浓花绿黄。屏风送雨来，早起芙蓉香。</span><br><span class=line>花界无生地，慈宫有相年。规模随胜势，耳意极神仙。万象随师论，三孤得诫前。一闻虽有感，勤倚已无缘。世途空无事，浮图独有权。本师将已偶，行远未遭妍。谷忽横戎塞，天威启曲田。关山高入汉，关界本成仙。日日云楼静，秋郊朔漠旋。山河分手去，甲合数西偏。鸡犬随人聚，邹差历日终。延嗟感恩日，激鼓下朝空。更有千年雁，飞飞一夜天。</span><br><span class=line>朝发淇水南，将寻北燕路。魏家旧城阙，寥落无人住。独自哭辽城，谁人问劳许。与君相送远，往事辞家住。出门无处人，望日不能饭。见君还自取，不作流中宿。忆昔恶应看，少年半成竹。今年三十六，不敢暂欢苦。我家能种芳，岁暮日日暮。不属百丈来，犹无一少客。眼看人欲聘，已学天阴黑。自古实不知，倾朱还刻况。为之即有所，何用偷无种。但好度三年，一理无虚。</span><br><span class=line>秋天清，寒夜滴沈沈沈。不用雄雄风，羇骚即隐关。一朝四州上，君子名重关。博山最高山，大道自然通。彭州府中寺，举世同老农。窜尔俱往时，形影在乾坤。日夕望远近，涕泪悲飞鸿。况当春序迟，及念怀义同。古才百推至，言语千岁风。盛时且献恩，所用齿冠风。回首北斗上，弥笑不见功。并苦千里中，得丧时丁风。揽辔到北海，唯余天下中。昔日又一日，何须变穷通。</span><br><span class=line>月出海门寻不得，中夜一夜一绳出。欹斜时见人寂莫，林猨犬吠人梦起。风飘野鸟入簷下，月下马头秋欲暮。知君久离旧山谪，玉堂掩锁开缄宿。南邻野叟来往时，北上重人知意迟。脱却珠眉蟾烂熳，宫女看来白玉札。扬姬小女唱豪颐，琵琶瑟瑟如玉琴。太行十二九盘路，楼上日月生光芒。君凡无言即相觅，云是龙高不得遗。假似众童相向下，仰摇直至落轮刀。初宿大名复如此，人间便得何时断。身逐霓旌动故山，穷时愿得长生药。</span><br><span class=line>1800it [01:56, 15.50it/s]</span><br><span class=line>夜梦归乡远，离书到岳阳。马归三岛上，诗卷六州傍。亭树千家茂，邻家数若忙。海鱼惊戴褐，家吏灌拏床。照榻初朝局，谙蛬思旅菜。老夫欺酒伴，胆炙置茶香。米足侵炎利，柴曾擘早凉。外缘名寄鹤，林灶病为场。念后身忘地，安知道路长。心清通市井，醉臥倚肩床。若问天涯兴，空无白太长。荒疆归路永，垂白看头长。</span><br><span class=line></span><br><span class=line>198it [00:12, 16.39it/s]</span><br><span class=line>训练损失为0.47638893872499466</span><br><span class=line>春江潮水连海平，海上明月共潮生。灩灩随波千万里，何处春江无月明？江流宛转遶芳甸，月照花林皆似霰。空里流霜不觉飞，汀上白沙看不见。江天一色无纤尘，皎皎空中孤月轮。江畔何人初见月，江月何年初照人？人生代代无穷已，江月年年秖相似。不知江月待何人？但见长江共云阔，空使人心不同別。世人爱与贫居多，欲折还归牧童戏。昨宵寅话敬平事，泪下禅心转江汉。</span><br></pre></table></figure><h3 id=步骤-9-定义预测函数并且测试生成结果><a class=markdownIt-Anchor href=#步骤-9-定义预测函数并且测试生成结果></a> 步骤 9 定义预测函数并且测试生成结果</h3><figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br></pre><td class=code><pre><span class=line>%cd /home/ma-user/work/LSTM_poem-master</span><br><span class=line></span><br><span class=line><span class=keyword>def</span> <span class="title function_">userTest</span>():</span><br><span class=line>    <span class=built_in>print</span>(<span class=string>"正在初始化......"</span>)</span><br><span class=line>    <span class=comment># 加载数据</span></span><br><span class=line>    datas = np.load(<span class=string>"tang.npz"</span>, allow_pickle=<span class=literal>True</span>)</span><br><span class=line>    data = datas[<span class=string>'data'</span>]</span><br><span class=line>    ix2word = datas[<span class=string>'ix2word'</span>].item()</span><br><span class=line>    word2ix = datas[<span class=string>'word2ix'</span>].item()</span><br><span class=line></span><br><span class=line>    <span class=comment># 定义模型</span></span><br><span class=line>    model = PoetryModel(<span class=built_in>len</span>(ix2word), Config.embedding_dim, Config.hidden_dim)</span><br><span class=line></span><br><span class=line>    <span class=comment># 指定模型文件路径</span></span><br><span class=line>    model_path = <span class=string>'/home/ma-user/work/LSTM_poem-master/Output/model_epoch_19.pth'</span>  <span class=comment># 假设文件名为 model_epoch_final.pth</span></span><br><span class=line>    <span class=keyword>if</span> os.path.isfile(model_path):</span><br><span class=line>        <span class=comment># 加载模型</span></span><br><span class=line>        model.load_state_dict(t.load(model_path, map_location=t.device(<span class=string>'cpu'</span>)))</span><br><span class=line>        <span class=built_in>print</span>(<span class=string>"模型加载成功！\n"</span>)</span><br><span class=line>    <span class=keyword>else</span>:</span><br><span class=line>        <span class=built_in>print</span>(<span class=string>"模型文件不存在，请检查路径！"</span>)</span><br><span class=line>        <span class=keyword>return</span></span><br><span class=line></span><br><span class=line>    <span class=comment># 配置GPU或CPU</span></span><br><span class=line>    <span class=keyword>if</span> Config.use_gpu:</span><br><span class=line>        model.to(t.device(<span class=string>'cuda'</span>))</span><br><span class=line>    <span class=built_in>print</span>(<span class=string>"初始化完成！\n"</span>)</span><br><span class=line></span><br><span class=line>    <span class=comment># 用户交互部分</span></span><br><span class=line>    <span class=keyword>while</span> <span class=literal>True</span>:</span><br><span class=line>        <span class=built_in>print</span>(<span class=string>"欢迎使用唐诗生成器，\n"</span></span><br><span class=line>              <span class=string>"输入1 进入首句生成模式\n"</span></span><br><span class=line>              <span class=string>"输入2 进入藏头诗生成模式\n"</span>)</span><br><span class=line>        mode = <span class=built_in>int</span>(<span class=built_in>input</span>())</span><br><span class=line>        <span class=keyword>if</span> mode == <span class=number>1</span>:</span><br><span class=line>            <span class=built_in>print</span>(<span class=string>"请输入您想要的诗歌首句，可以是五言或七言"</span>)</span><br><span class=line>            start_words = <span class=built_in>str</span>(<span class=built_in>input</span>())</span><br><span class=line>            gen_poetry = <span class=string>''</span>.join(generate(model, start_words, ix2word, word2ix))</span><br><span class=line>            <span class=built_in>print</span>(<span class=string>"生成的诗句如下：%s\n"</span> % (gen_poetry))</span><br><span class=line>        <span class=keyword>elif</span> mode == <span class=number>2</span>:</span><br><span class=line>            <span class=built_in>print</span>(<span class=string>"请输入您想要的诗歌藏头部分，不超过16个字，最好是偶数"</span>)</span><br><span class=line>            start_words = <span class=built_in>str</span>(<span class=built_in>input</span>())</span><br><span class=line>            <span class=comment># 确保 gen_acrostic 函数存在并且正确实现</span></span><br><span class=line>            gen_poetry = <span class=string>''</span>.join(gen_acrostic(model, start_words, ix2word, word2ix))</span><br><span class=line>            <span class=built_in>print</span>(<span class=string>"生成的诗句如下：%s\n"</span> % (gen_poetry))</span><br><span class=line></span><br><span class=line><span class=keyword>if</span> __name__ == <span class=string>'__main__'</span>:</span><br><span class=line>    userTest()</span><br></pre></table></figure><p>输出结果如下：<h3 id=步骤-10-查看训练输出的模型><a class=markdownIt-Anchor href=#步骤-10-查看训练输出的模型></a> 步骤 10 查看训练输出的模型</h3><p>打开 notebook 中的如下 Output 文件，可以查看到代码训练的输出模型内容。</div><footer class=post-footer><div class=reward-container><div>我很可爱，请给我钱！</div><button>赞赏</button><div class=post-reward><div><img alt="Tarik Von 微信" src=/images/wechatpay.png><span>微信</span></div></div></div><div class=post-tags><a href=/tags/Python/ rel=tag># Python</a><a href=/tags/NLP/ rel=tag># NLP</a><a href=/tags/LSTM/ rel=tag># LSTM</a><a href=/tags/RNN/ rel=tag># RNN</a><a href=/tags/Huawei-Cloud/ rel=tag># Huawei Cloud</a><a href=/tags/ModelArts/ rel=tag># ModelArts</a><a href=/tags/Jupyter-Notebook/ rel=tag># Jupyter Notebook</a></div><div class=post-nav><div class=post-nav-item><a title="Notes: INFO-200: Information Systems Analysis (Spring, 2024)" href=/2024/07/07/info-200/ rel=prev> <i class="fa fa-angle-left"></i> Notes: INFO-200: Information Systems Analysis (Spring, 2024) </a></div><div class=post-nav-item><a title="华为 HCIP - AI EI Developer 学习笔记" href=/2024/11/05/note-HCIP/ rel=next> 华为 HCIP - AI EI Developer 学习笔记 <i class="fa fa-angle-right"></i> </a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2025</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>Tarik Von</span><span> </span><a href=https://beian.miit.gov.cn/ target=_blank>闽ICP备2025086651号-1</a></div><div class=wordcount><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-chart-line"></i> </span> <span title=站点总字数>42k</span> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-coffee"></i> </span> <span title=站点阅读时长>2:32</span> </span></div><div class=powered-by>由 <a href=https://www.tarikvon.cn:8001/>Hexo</a> & <a href=https://theme-next.js.org/pisces/ rel=noopener target=_blank>NexT.Pisces</a> 强力驱动</div><script color=126,0,255 count=99 opacity=0.5 src=/lib/theme-next-canvas-nest/canvas-nest.js zindex=-1></script></div></footer><div aria-label=返回顶部 class=back-to-top role=button><i class="fa fa-arrow-up fa-lg"></i><span>0%</span></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><script alpha=0.6 size=300 src=https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js zindex=-1></script><script crossorigin=anonymous integrity=sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY= src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js></script><script crossorigin=anonymous integrity=sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao= src=https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js></script><script src=/js/comments.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/next-boot.js></script><script src=/js/pjax.js></script><script class=next-config data-name=enableMath type=application/json>false</script><link crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css integrity=sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM= rel=stylesheet>